% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_observation_regression.R
\name{get_observation_regression}
\alias{get_observation_regression}
\title{Run a Machine Learning algorithm on a dataset.}
\usage{
get_observation_regression(
  data,
  k_foldcv,
  model_name,
  n,
  performance_metric = mse
)
}
\arguments{
\item{data}{The data should be a single data frame where:
All feature columns (X) come first.
The last column is the target variable (y), named as target.
See [calc_nreps()] for details.}

\item{k_foldcv}{Integer specifying the number of folds to use in k-fold cross-validation.}

\item{model_name}{Character string specifying the predictive model to fit.
Supported options are:
\describe{
  \item{"linear"}{Linear regression model using \code{lm()}, for regression tasks only.}
  \item{"random_forest"}{Random Forest model using \code{randomForest()}, supports both regression and classification.}
  \item{"svm"}{Support Vector Machine model using \code{svm()} from \code{e1071}, supports both regression and classification.}
  \item{"decision_tree"}{Decision tree model using \code{rpart()}, supports both regression and classification.}
  \item{"boosting"}{Gradient Boosting model using \code{gbm()}, with distribution set to "gaussian" for regression and "bernoulli" for classification.}
}}

\item{n}{number of observations to generate.}

\item{performance_metric}{A function to evaluate model predictions.
It should take two arguments: actual values and predicted values, and return a numeric performance score.
If \code{NULL}, defaults to mean squared error for regression and accuracy for classification.}
}
\value{
vector of observed performance values
}
\description{
Runs cross-validation multiple times to evaluate a machine learning model's performance on a dataset.
}
\details{
@section References:
- F. Campelo
   CAISEr: Comparing Algorithms with Iterative Sample-size Estimation in R


  Additional model-specific parameters can be passed through the \code{model_params} list argument.
  For classification tasks, the \code{target} variable must be a factor; for regression, it must be numeric.
}
\examples{

Regression algorithm
# Loading dataset
library(MASS)
data("Boston")

# Feature matrix and target
X <- Boston[, -14]
y <- Boston$medv
boston <- as.data.frame(X)
boston$target <- y # Rename the target column to 'target' as expected by the function

mse_results <- get_observation_regression(boston, k_foldcv = 5, model_name = "linear", n = 3)
print(mse_results)

# Using another performance metric

r2_metric <- function(actual, predicted) {
1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)}
r2_results <- get_observation_regression(boston, k_foldcv = 5, model_name = "random_forest", n = 3, performance_metric = r2_metric)
print(r2_results)


}
\seealso{
[calc_nreps_regression()]
}
\author{
Prajwel Venkatasubramaniyan (\email{prajwel16@gmail.com})
}
